<!DOCTYPE html><html lang="en" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Paper Reading 2: R-CNN, Fast R-CNN, Faster R-CNN | Yeedrag's website :D</title><meta name="author" content="Yeedrag"><meta name="copyright" content="Yeedrag"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="For this week, I decided to read a trio, the trio of regional based CNNs. R-CNNs are usually used in object detection tasks. Theres also Mask R-CNN that can do segmentation but I won’t talk about that">
<meta property="og:type" content="article">
<meta property="og:title" content="Paper Reading 2: R-CNN, Fast R-CNN, Faster R-CNN">
<meta property="og:url" content="http://example.com/2024/03/02/Paper-Reading-2-R-CNN-Fast-R-CNN-Faster-R-CNN/index.html">
<meta property="og:site_name" content="Yeedrag&#39;s website :D">
<meta property="og:description" content="For this week, I decided to read a trio, the trio of regional based CNNs. R-CNNs are usually used in object detection tasks. Theres also Mask R-CNN that can do segmentation but I won’t talk about that">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://pbs.twimg.com/profile_images/1610231810201636870/Nj3OUXrQ_400x400.jpg">
<meta property="article:published_time" content="2024-03-03T05:54:46.000Z">
<meta property="article:modified_time" content="2025-02-01T00:44:05.177Z">
<meta property="article:author" content="Yeedrag">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pbs.twimg.com/profile_images/1610231810201636870/Nj3OUXrQ_400x400.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2024/03/02/Paper-Reading-2-R-CNN-Fast-R-CNN-Faster-R-CNN/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><meta/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: false,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Paper Reading 2: R-CNN, Fast R-CNN, Faster R-CNN',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-01-31 18:44:05'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/modify.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pbs.twimg.com/profile_images/1610231810201636870/Nj3OUXrQ_400x400.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">30</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><hr class="custom-hr"/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background: transparent"><nav id="nav"><span id="blog-info"><a href="/" title="Yeedrag's website :D"><span class="site-name">Yeedrag's website :D</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Paper Reading 2: R-CNN, Fast R-CNN, Faster R-CNN</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-03-03T05:54:46.000Z" title="Created 2024-03-02 23:54:46">2024-03-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-02-01T00:44:05.177Z" title="Updated 2025-01-31 18:44:05">2025-01-31</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">1.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>7mins</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>For this week, I decided to read a trio, the trio of regional based CNNs. R-CNNs are usually used in object detection tasks. Theres also Mask R-CNN that can do segmentation but I won’t talk about that (or maybe I will).</p>
<h2 id="rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation-2013"><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1311.2524.pdf">Rich feature hierarchies for accurate object detection and semantic segmentation (2013)</a></h2>
<p>This is the first paper that proposed the idea of using regional proposals with CNNs to do object detection.</p>
<p>The whole framework is quite interesting, and I will introduce them one by one.</p>
<p><img src="R-CNN-Flow.png" alt="R-CNN-Flow"></p>
<h3 id="region-proposal">Region Proposal</h3>
<p>The first step of R-CNN is generating a bunch of region proposals for the CNN to work with. You can think of these regional proposals as rough bounding boxes made from grouping color, brightness and more. In R-CNN, they generated 2000 class-independent regional proposals, and they used a technique called selective search to generate these proposals.</p>
<p><img src="selective.png" alt="Selective"></p>
<h3 id="cnn">CNN</h3>
<p>Next, they feed the region proposals into a CNN, that will extract the features and send it to a SVM classifier. The CNN architecture they used is the AlexNet we’ve read last week. A problem here is at that time, there are scarce labeled object detection images to use, so they couldn’t directly train the CNN on those. The solution they found was to first train the CNN with a big dataset only with image-level annotations (so bounding box labels are not available in the dataset), then they would replace the classification layer with a random layer and fine-tune the model with a small set of labeled actual data.</p>
<p>Since the region proposals have various shapes, they will first also include some pixels around the region (16 in the paper), and then naively warps them into the designated shape.</p>
<p>They treat all region proposals with &gt;= 0.5 IoU overlap with a ground truth box as positives for that box’s class and rest as negatives.</p>
<h3 id="svm-classifier">SVM Classifier</h3>
<p>After producing a feature vector from the CNN, they send the vector into a SVM to classify the result of each region proposal. In this part, they treat all region proposals with full ground truth mask as positives and the rest as negatives.</p>
<p>After reading this, I had two big questions.</p>
<ol>
<li>
<p>Why do we have different definitions for positive examples?</p>
</li>
<li>
<p>Why do we not directly use the output from the CNN, instead we chose to separately train another SVM?</p>
</li>
</ol>
<p>They actually answered both questions in appendix B in the paper.</p>
<ol>
<li>
<p>They believe the difference in how positives and negatives are defined is not fundamentally important, and rather is caused by how the fine-tuning data is limited, and they had to introduce data that prevents overfitting but also might be suboptimal.</p>
</li>
<li>
<p>They actually did try directly applying soft-max on the final layer, and the performance dropped from 54.2% to 50.9% mAP. They conjectured this as an affect of the definition of the examples, and hinted that it may be possible to not include the SVM and achieve similar results, while speeding up the whole model. (Basically they do not know why it’s worse but had to come up with an explanation for the paper XD)</p>
</li>
</ol>
<p>Also, in the appendix they also did another bounding box regression after the SVM to further refine the bounding box.</p>
<h2 id="fast-r-cnn-2015"><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1504.08083.pdf">Fast R-CNN (2015)</a></h2>
<p>After reading about R-CNN, now we will look at Fast R-CNN, which aims to solve a few big problems with R-CNN.</p>
<p>R-CNN has three main big problems:</p>
<ol>
<li>
<p>Training is a multi-stage pipeline.</p>
</li>
<li>
<p>Training is very expensive and time consuming.</p>
</li>
<li>
<p>Detection is slow, since every picture needed to be sliced with several region proposals, and run a CNN on every single one of them.</p>
</li>
</ol>
<p>An attempt to fix this problem is SPPNet, which basically generates a huge feature map with CNN from the original image first, then do region proposals on top of it.</p>
<p><a target="_blank" rel="noopener" href="https://analyticsindiamag.com/r-cnn-vs-fast-r-cnn-vs-faster-r-cnn-a-comparative-guide/">image comparing SPPNet and R-CNN</a><br>
<img src="compare.png" alt="compare"></p>
<p>Now, a big problem caused by SPPNet is the inability to back propagate and update weights below the spatial pyramid pooling layer. The reasoning given in the paper is due to each RoI can have a big receptive field and making the whole process inefficient (Im not gonna lie I didn’t understand this fully).</p>
<h3 id="roi-pooling-layer">RoI Pooling Layer</h3>
<p>They replaced the SPP layer with a more efficient RoI pooling layer, which you can think of is a single layer version of the SPP layer.</p>
<p>(Note: I think RoI pooling should be worse than SPP, due to not captureing spatial relationships like SPP does, but I’m guessing they use it because of the efficiency, and it enables end-to-end back propagation training, I will need to read the SPPNet paper some day to understand more, and I will update this blog later on).</p>
<h3 id="softmax-regressor-bounding-box-regressor">Softmax Regressor/Bounding Box Regressor</h3>
<p>In SPPNet and Fast R-CNN, they both chose to use a softmax regressor in the end instead of the individual SVMs in the original R-CNN, which can make the speed faster. They also included the Bounding box regressor that was in the appendix of the original R-CNN.</p>
<p>After this I questioned: Why does the original R-CNN paper not use softmax regression for the classification step, and chose to use SVMs?</p>
<p>This question of comparing performance is acutally in the paper. They did test using SVM and softmax, and SVM did do a better job, but the performance increase is small, and the computation is not worth it.</p>
<h2 id="faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks-2015"><a target="_blank" rel="noopener" href="https://papers.nips.cc/paper_files/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (2015)</a></h2>
<p>Again, Fast R-CNN is much faster compared to R-CNN, but still slow due to the need to do selective search to generate region proposals, which is quite slow in the long run.</p>
<p>To solve this, Faster R-CNN introduced Regional Proposal Networks (RPN), which is a fully convolutional network that predicts several proposals, and also giving them a probability of having an object and the label for it.</p>
<p>First, a sliding window will go through the last layer for the feature extractor, generating several n x n regions of the feature map.</p>
<p>In the window, they will also use several “Anchor boxes”, which are various fix-sized regions that gives a rough outline of where the object might be. One important thing to note is these anchor boxes are translation invariant, which means if you translate an object, the same function should be able to predit the same proposal in either location. This makes it really efficient as other similar methods do not have the invariance.</p>
<p>The regions will then be reduced dimensions, and sent to two sibling layers: one for box regression (which will also encode the coordinates of the anchor boxes), other for classification. This part is shared through every region, so it is quite efficient.</p>
<h2 id="final-words">Final Words</h2>
<p>Honestly, I was quite busy this week, and there are quite a few points I felt like I wasn’t completely sure, so I will likely go back to this and understand it further in the future.</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI/">AI</a></div><div class="post_share"></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://pbs.twimg.com/profile_images/1610231810201636870/Nj3OUXrQ_400x400.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Yeedrag</div><div class="author-info__description">A nobody trying to become somebody</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">30</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/yeedrag"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/yeedrag" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:yeedrag0722@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Thanks for passing by!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation-2013"><span class="toc-number">1.</span> <span class="toc-text">Rich feature hierarchies for accurate object detection and semantic segmentation (2013)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#region-proposal"><span class="toc-number">1.1.</span> <span class="toc-text">Region Proposal</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cnn"><span class="toc-number">1.2.</span> <span class="toc-text">CNN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#svm-classifier"><span class="toc-number">1.3.</span> <span class="toc-text">SVM Classifier</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#fast-r-cnn-2015"><span class="toc-number">2.</span> <span class="toc-text">Fast R-CNN (2015)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#roi-pooling-layer"><span class="toc-number">2.1.</span> <span class="toc-text">RoI Pooling Layer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#softmax-regressor-bounding-box-regressor"><span class="toc-number">2.2.</span> <span class="toc-text">Softmax Regressor&#x2F;Bounding Box Regressor</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks-2015"><span class="toc-number">3.</span> <span class="toc-text">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (2015)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#final-words"><span class="toc-number">4.</span> <span class="toc-text">Final Words</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/01/Random-thoughts-and-math/" title="Random thoughts and math">Random thoughts and math</a><time datetime="2025-03-01T21:43:22.000Z" title="Created 2025-03-01 15:43:22">2025-03-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/01/End-of-2024-New-Year-s-Resolution/" title="End of 2024 + New Year's Resolution">End of 2024 + New Year's Resolution</a><time datetime="2025-01-01T07:08:15.000Z" title="Created 2025-01-01 01:08:15">2025-01-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/25/Paper-Reading-3-BERT-RoBERTa-LoRA/" title="Paper Reading 3: BERT/RoBERTa/LoRA">Paper Reading 3: BERT/RoBERTa/LoRA</a><time datetime="2024-12-25T21:40:20.000Z" title="Created 2024-12-25 15:40:20">2024-12-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/08/22/2024-Summer-REU-experience/" title="2024 Summer REU experience">2024 Summer REU experience</a><time datetime="2024-08-22T20:15:09.000Z" title="Created 2024-08-22 15:15:09">2024-08-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/05/14/End-of-Freshman-Year/" title="End of Freshman Year">End of Freshman Year</a><time datetime="2024-05-15T01:35:14.000Z" title="Created 2024-05-14 20:35:14">2024-05-14</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2025 By Yeedrag</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script></div></body></html>