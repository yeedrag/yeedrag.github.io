<!DOCTYPE html><html lang="en" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>2025/2026 AI Safety Fellowship Application Experiences and Results | Yeedrag's website :D</title><meta name="author" content="Yeedrag"><meta name="copyright" content="Yeedrag"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="I will document my experiences applying to various AI safety research fellowships for this year. I will try to be as detailed as possible, but I might have forgotten some details. I hope this blog wil">
<meta property="og:type" content="article">
<meta property="og:title" content="2025&#x2F;2026 AI Safety Fellowship Application Experiences and Results">
<meta property="og:url" content="https://yeedrag.github.io/2025/12/17/2026-Winter-AI-Safety-Fellowship-Application-Experiences-Results/index.html">
<meta property="og:site_name" content="Yeedrag&#39;s website :D">
<meta property="og:description" content="I will document my experiences applying to various AI safety research fellowships for this year. I will try to be as detailed as possible, but I might have forgotten some details. I hope this blog wil">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://pbs.twimg.com/profile_images/1610231810201636870/Nj3OUXrQ_400x400.jpg">
<meta property="article:published_time" content="2025-12-17T08:23:10.000Z">
<meta property="article:modified_time" content="2026-01-19T19:58:20.829Z">
<meta property="article:author" content="Yeedrag">
<meta property="article:tag" content="Life">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="AI Safety">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pbs.twimg.com/profile_images/1610231810201636870/Nj3OUXrQ_400x400.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "2025/2026 AI Safety Fellowship Application Experiences and Results",
  "url": "https://yeedrag.github.io/2025/12/17/2026-Winter-AI-Safety-Fellowship-Application-Experiences-Results/",
  "image": "https://pbs.twimg.com/profile_images/1610231810201636870/Nj3OUXrQ_400x400.jpg",
  "datePublished": "2025-12-17T08:23:10.000Z",
  "dateModified": "2026-01-19T19:58:20.829Z",
  "author": [
    {
      "@type": "Person",
      "name": "Yeedrag",
      "url": "https://yeedrag.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://yeedrag.github.io/2025/12/17/2026-Winter-AI-Safety-Fellowship-Application-Experiences-Results/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><meta/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: false,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '2025/2026 AI Safety Fellowship Application Experiences and Results',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/modify.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">

<link rel="stylesheet" href="/css/collapse.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div class="bg-animation" id="web_bg" style="background-image: url(https://wallpaperaccess.com/full/1874650.png);"></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background: transparent;"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Yeedrag's website :D</span></a><a class="nav-page-title" href="/"><span class="site-name">2025/2026 AI Safety Fellowship Application Experiences and Results</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">2025/2026 AI Safety Fellowship Application Experiences and Results</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-12-17T08:23:10.000Z" title="Created 2025-12-17 00:23:10">2025-12-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2026-01-19T19:58:20.829Z" title="Updated 2026-01-19 11:58:20">2026-01-19</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>12mins</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>I will document my experiences applying to various AI safety research fellowships for this year. I will try to be as detailed as possible, but I might have forgotten some details. I hope this blog will not be seen as a brag, but rather an unbiased documentary aimed to help people understand more about the AI safety fellowship and what the process looks like.</p>
<h1 id="my-background">My background</h1>
<p>I’ll maybe add more information on my background later, but I think you can infer most information from the resume.</p>
<h2 id="references">References</h2>
<p>I had two references:</p>
<p>(1) Manager from my summer internship at an insurance company where I did red teaming research.<br>
(2) Professor with whom I did a REU research in my freshman year, with a first-author paper produced in IEEE conference (non-safety).</p>
<p>I had great relationships with both references, and both were more than happy to write strong references for me.</p>
<h2 id="resume">Resume</h2>
<p>I used 2 resumes across applications. The first one was for SPAR:</p>
<p><img src="resume_old.png" alt="old_resume"></p>
<p>I updated my resume significantly afterwards, and all other fellowships are applied using this resume:</p>
<p><img src="resume_new.png" alt="new_resume"></p>
<h1 id="programs-i-applied-to">Programs I applied to</h1>
<h2 id="supervised-program-for-alignment-research-spar"><a target="_blank" rel="noopener" href="https://sparai.org/">Supervised Program for Alignment Research (SPAR)</a></h2>
<p>Note: This is for the 2025 fall cohort.</p>
<p><strong>Format</strong>: Online<br>
<strong>Paid</strong>: No<br>
<strong>References</strong>: Not Required<br>
<strong>Offer</strong>: Yes<br>
<strong>Time Spent</strong>: 8hr (initial application) + 1hr (interviews) = 9hr</p>
<p>The format for SPAR is quite simple. On their website, you can apply for various projects. Each project has specific questions, and you have to write an essay for each prompt. Apart from project-dependent questions, there is also a general application you have to fill out.</p>
<p>I applied to 5 of them, of which 2 did not require any project questions. If the mentor is interested in you, they will ask to arrange a short, 30-minute interview. Both of my interviews focused on the project and the content I wrote for the mentor questions, so I would suggest spending some time working on those essays.</p>
<p>Interestingly, I originally received an email saying I was rejected from all projects. But the two mentors I interviewed with personally contacted me afterwards, asking whether I got in SPAR, and they were surprised that I didn’t, as there seemed to be a misunderstanding of the selection mechanism. After talking to Kairos, I was able to successfully participate in SPAR!</p>
<p>The acceptance rate for this specific cohort was around 18%, although it’s highly project-dependent. My recommendation is to apply for several (~5), and don’t just pick ones with famous mentors!</p>
<h2 id="ml-alignment-theory-scholars-mats"><a target="_blank" rel="noopener" href="https://www.matsprogram.org/">ML Alignment &amp; Theory Scholars (MATS)</a></h2>
<p><strong>Format</strong>: In-person<br>
<strong>Paid</strong>: Yes<br>
<strong>References</strong>: Required (2)<br>
<strong>Offer</strong>: No (1 work test)<br>
<strong>Time Spent</strong>: 4hr (general application) + 13 hr (Stream specific applications) + 2hr (CodeSignal) + 3hr (Work test) = 22hr</p>
<p>MATS is likely one of the most famous AI Safety research programs out there, with an acceptance rate of around 5~8%. (This cohort had an 8% acceptance rate, I heard.)</p>
<p>There is a general application you need to do (as usual), but unlike SPAR, you apply to streams instead. You apply to mentors that you are interested in, and either come up with a project during the application or discuss with the mentor after acceptance.</p>
<p>(I highly recommend spending some time on the general application, because most fellowships ask similar questions, and it’s mostly copy-pasting your polished version from MATS.)</p>
<p>After the initial applications, you will get a CodeSignal ICA assessment that is unproctored (but doesn’t allow AI). I would recommend spending some time learning to write OOP and contained code, as the ICA assessment focuses on refactoring and changing previous implementations, which can be quite chaotic if you don’t write code that’s easy to refactor. I was able to ace the test (600/600) with some time to spare. The average MATS applicant has a Codesignal score of 540, but I would not worry too much if you didn’t get a good score. I know people who got in with only 500 or even 480, and most get rejected with 600/600, so many mentors don’t weigh the score heavily.</p>
<p>After the CodeSignal, mentors will start sending out interview or work-test invites. I got a work test from a mentor I didn’t apply to (apparently, they thought I was a good fit) on creating a research proposal, but I didn’t get an offer in the end.</p>
<h2 id="center-for-human-compatible-artificial-intelligence-chai"><a target="_blank" rel="noopener" href="https://humancompatible.ai/">Center for Human-Compatible Artificial Intelligence (CHAI)</a></h2>
<p>Note: This is for the 2026 summer intern application.</p>
<p><strong>Format</strong>: In-person<br>
<strong>Paid</strong>: Yes<br>
<strong>References</strong>: No<br>
<strong>Offer</strong>: ?<br>
<strong>Time Spent</strong>: 1hr (initial application) + 2hr (OA) = 3hr</p>
<p>Don’t have much to say about CHAI yet, as it’s still ongoing (though I should have gotten a next-round invite ages ago…).</p>
<p>They do not use CodeSignal for their OA. Instead, they use another platform with 3 problems to choose from: MCTS, Decision Tree, and BPE. I personally chose the problem to implement a variant of BPE, and I think it wasn’t too difficult as long as you know how BPE works. I scored 600/600 on the OA. I’ve heard that MCTS is very hard, and the Decision Tree one was pretty tricky to implement. Basically, do BPE!</p>
<p>I do want to share that they accidentally sent everyone the 2nd-stage email, and then, after an hour, sent a rejection email to those who didn’t actually get into the second round. Weirdly, after a week, they sent another rejection email! I know some people who got pretty upset about this, and I think they could’ve done better here.</p>
<h2 id="mentorship-for-alignment-research-students-mars"><a target="_blank" rel="noopener" href="https://www.cambridgeaisafety.org/mars">Mentorship for Alignment Research Students (MARS)</a></h2>
<p><strong>Format</strong>: Online (With first two weeks at Cambridge)<br>
<strong>Paid</strong>: No<br>
<strong>References</strong>: No<br>
<strong>Offer</strong>: No (2nd round)<br>
<strong>Time Spent</strong>: 1hr (Initial application) + 2hr (2nd round project questions) = 4hr</p>
<p>MARS is quite similar to SPAR, but they first use an initial application to filter out people, then do the project-specific 2nd-round application. This design was a bit annoying because none of the projects were actually interesting to me!</p>
<p>Also, in the second-round rejection email, they messed up, so you can see every single participant who was rejected that round. Definitely didn’t give me the best impression, but I also know people who got great offers from the program.</p>
<h2 id="constellation-astra"><a target="_blank" rel="noopener" href="https://www.constellation.org/programs/astra-fellowship">Constellation Astra</a></h2>
<p><strong>Format</strong>: In-person<br>
<strong>Paid</strong>: Yes<br>
<strong>References</strong>: Required (2) -&gt; Sync with MATS<br>
<strong>Offer</strong>: YES<br>
<strong>Time Spent</strong>: 3hr (initial application) + [2hr (CodeSignal)] + 7hr (Work test) + 5hr (Research Assessment) + 0.5hr (Interview) = 17.5 hr (15.5 excluding CodeSignal)</p>
<p>Astra is also stream-specific (though streams are not per-mentor like MATS), allowing you to choose tracks like field building, empirical, security, and more (I only applied to the empirical track). The good thing about Astra is that they collaborate with MATS, so you can reuse the same codesignal score and references!</p>
<p>For the empirical track: After the application (and CodeSignal), there will be a 5-hour research assessment, where they will give you a research topic, and you will have to come up with hypotheses, conduct experiments, and create a 30-minute presentation all within the timeframe.</p>
<p>At the same time, you might also get work tests from certain streams. For example, I got a work test from Redwood and UK AISI, which are again prompts to write an essay on. It can be asking your thoughts on a specific phenomenon/agenda, or thinking of research questions.</p>
<p>Getting a work test is not required to get an interview. I got an interview with DeepMind (specifically with David Lindner) without any prior work tests, so I assume this is also mentor- or org-dependent.</p>
<p>The interview with GDM was 30 minutes. We started off with a technical coding question, where he pulled out a Colab notebook with a question that I had to solve. The question doesn’t require any specific algorithmic knowledge and instead tests your general problem-solving skills. I didn’t actually solve it because we only had like 7 minutes, but I verbally explained my solution, and he seems satisfied with it. After that, he started asking me about a specific research proposal I mentioned in my application, which I honestly haven’t thought of in a while (big blunder!).</p>
<p>I felt horrible after the interview because I thought I didn’t do well, but it turns out it was enough to get accepted by Scott Emmons! This is the offer I ended up accepting, as I wanted to return to Constellation and work at Berkeley.</p>
<h2 id="era"><a target="_blank" rel="noopener" href="https://erafellowship.org/">ERA</a></h2>
<p><strong>Format</strong>: In-person<br>
<strong>Paid</strong>: Yes<br>
<strong>References</strong>: Required (2) -&gt; Only asks after passing the first round<br>
<strong>Offer</strong>: Yes<br>
<strong>Time Spent</strong>: 2hr (initial application) + 0.5hr (First interview) + 1hr (second interview) = 3.5hr</p>
<p>ERA’s application process is my favorite one by far.</p>
<p>There is first an initial application to filter out people, and then they will send out an asynchronous, online interview. Basically, you will get a prompt, 30 seconds to think, and 5 minutes to record your response. You can re-record once if you mess up, but I didn’t use any re-recordings.</p>
<p>After the first interview, there is a final 1-hour interview round (with a real person!). I interviewed with Dave Banerjee from IAPS. It was a pretty difficult interview with a lot of abstract questions, and I would say it requires a solid understanding of the AI Safety landscape and understanding X-risk issues.</p>
<p>Overall, this was my favorite process so far. The questions challenged me to think more deeply about my perspectives on AI Safety, which was super valuable to me.</p>
<p>I believe the rates were something like 20% for the second round, 3% for the final round, and 1% for the offer. Pretty cool that I got accepted!</p>
<h2 id="london-ai-safety-research-labs-lasr"><a target="_blank" rel="noopener" href="https://www.lasrlabs.org/">London AI Safety Research Labs (LASR)</a></h2>
<p><strong>Format</strong>: In-person<br>
<strong>Paid</strong>: Yes<br>
<strong>References</strong>: No<br>
<strong>Offer</strong>: (Declined final round interview after Astra acceptance)<br>
<strong>Time Spent</strong>: 2hr (initial application) + 2hr (OA) = 4hr</p>
<p>The initial application is quite standard, so I won’t go into much detail.</p>
<p>After passing the initial stage, there is a CodeSignal MLE core assessment. This OA is evil. There are 10 MCQs, 1 algorithmic coding test, and 2 ML coding tests. The MCQs are on fundamental ML knowledge (PCA, F1 score, SVM, etc), the algorithmic coding test was around a lc medium, and the 2 ML coding tests were also on classical ML stuff (Bayesian, Gaussian Kernel, etc.)</p>
<p>I was shocked that LASR would give an OA that’s this fundamental, and I struggled a lot on this OA, essentially guessing a lot of the MCQs. I did get a pretty good score in the end (544/600), and I believe you can get into the next stage even with a score around 400 or 450, as the OA is really hard for everyone.</p>
<p>I got a final interview invite shortly after, but I declined after getting my Astra acceptance.</p>
<p>Sidenote: I’m not a big fan of how LASR operates. You have to get accepted first, form a team, and then they pair you with a project from their mentors. The issue is that you have no idea if there will be a project you are actually interested in! This seems pretty risky if you have a clear agenda or topic you want to work on.</p>
<h1 id="other-programs-i-didn-t-apply-to">Other Programs I didn’t apply to</h1>
<p>These are programs that I didn’t end up applying to, but have heard good things about them and you should consider applying if they are open!</p>
<h2 id="pibbss"><a target="_blank" rel="noopener" href="https://princint.ai/programs/fellowship/">PIBBSS</a></h2>
<p><strong>Format</strong>: In-person<br>
<strong>Paid</strong>: Yes<br>
<strong>References</strong>: No</p>
<h2 id="anthropic-fellows"><a target="_blank" rel="noopener" href="https://alignment.anthropic.com/2024/anthropic-fellows-program/">Anthropic Fellows</a></h2>
<p><strong>Format</strong>: In-person<br>
<strong>Paid</strong>: Yes<br>
<strong>References</strong>: Yes</p>
<h2 id="pivotal"><a target="_blank" rel="noopener" href="https://www.pivotal-research.org/">Pivotal</a></h2>
<p><strong>Format</strong>: In-person<br>
<strong>Paid</strong>: Yes<br>
<strong>References</strong>: Yes</p>
<h2 id="future-impact-group-fig"><a target="_blank" rel="noopener" href="https://futureimpact.group/fellowship">Future Impact Group (FIG)</a></h2>
<p><strong>Format</strong>: In-person<br>
<strong>Paid</strong>: Yes<br>
<strong>References</strong>: No</p>
<h2 id="ai-safety-camp"><a target="_blank" rel="noopener" href="https://www.aisafety.camp/">AI Safety Camp</a></h2>
<p><strong>Format</strong>: Online<br>
<strong>Paid</strong>: No<br>
<strong>References</strong>: No</p>
<h2 id="xlab-summer-fellow"><a target="_blank" rel="noopener" href="https://xrisk.uchicago.edu/fellowship/">XLab Summer Fellow</a></h2>
<p><strong>This is a summer position!</strong></p>
<p><strong>Format</strong>: In-person<br>
<strong>Paid</strong>: Yes<br>
<strong>References</strong>: ?</p>
<p>I’ll add more stuff if something comes up in my mind, but I’ll keep it as it is for now. If you have any questions, feel free to shoot an email / ask me on discord (id: yeedrag)!</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Life/">Life</a><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/AI-Safety/">AI Safety</a></div><div class="post-share"><div class="social-share" data-image="https://pbs.twimg.com/profile_images/1610231810201636870/Nj3OUXrQ_400x400.jpg" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="https://pbs.twimg.com/profile_images/1610231810201636870/Nj3OUXrQ_400x400.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Yeedrag</div><div class="author-info-description">A nobody trying to become somebody</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">36</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/yeedrag"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/yeedrag" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:yeedrag0722@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Thanks for passing by!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#my-background"><span class="toc-number">1.</span> <span class="toc-text">My background</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#references"><span class="toc-number">1.1.</span> <span class="toc-text">References</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#resume"><span class="toc-number">1.2.</span> <span class="toc-text">Resume</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#programs-i-applied-to"><span class="toc-number">2.</span> <span class="toc-text">Programs I applied to</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#supervised-program-for-alignment-research-spar"><span class="toc-number">2.1.</span> <span class="toc-text">Supervised Program for Alignment Research (SPAR)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ml-alignment-theory-scholars-mats"><span class="toc-number">2.2.</span> <span class="toc-text">ML Alignment &amp; Theory Scholars (MATS)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#center-for-human-compatible-artificial-intelligence-chai"><span class="toc-number">2.3.</span> <span class="toc-text">Center for Human-Compatible Artificial Intelligence (CHAI)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mentorship-for-alignment-research-students-mars"><span class="toc-number">2.4.</span> <span class="toc-text">Mentorship for Alignment Research Students (MARS)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#constellation-astra"><span class="toc-number">2.5.</span> <span class="toc-text">Constellation Astra</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#era"><span class="toc-number">2.6.</span> <span class="toc-text">ERA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#london-ai-safety-research-labs-lasr"><span class="toc-number">2.7.</span> <span class="toc-text">London AI Safety Research Labs (LASR)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#other-programs-i-didn-t-apply-to"><span class="toc-number">3.</span> <span class="toc-text">Other Programs I didn’t apply to</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#pibbss"><span class="toc-number">3.1.</span> <span class="toc-text">PIBBSS</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#anthropic-fellows"><span class="toc-number">3.2.</span> <span class="toc-text">Anthropic Fellows</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pivotal"><span class="toc-number">3.3.</span> <span class="toc-text">Pivotal</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#future-impact-group-fig"><span class="toc-number">3.4.</span> <span class="toc-text">Future Impact Group (FIG)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ai-safety-camp"><span class="toc-number">3.5.</span> <span class="toc-text">AI Safety Camp</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#xlab-summer-fellow"><span class="toc-number">3.6.</span> <span class="toc-text">XLab Summer Fellow</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/17/2026-Winter-AI-Safety-Fellowship-Application-Experiences-Results/" title="2025/2026 AI Safety Fellowship Application Experiences and Results">2025/2026 AI Safety Fellowship Application Experiences and Results</a><time datetime="2025-12-17T08:23:10.000Z" title="Created 2025-12-17 00:23:10">2025-12-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/16/Review-of-the-Soundcore-A30-Sleepbuds/" title="Review of the Soundcore A30 Sleepbuds">Review of the Soundcore A30 Sleepbuds</a><time datetime="2025-12-17T07:11:28.000Z" title="Created 2025-12-16 23:11:28">2025-12-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/31/OASIS-Blog/" title="OASIS Blog">OASIS Blog</a><time datetime="2025-08-31T07:38:09.000Z" title="Created 2025-08-31 00:38:09">2025-08-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/19/Learning-Dynamic-Programming-from-staircases/" title="Learning Dynamic Programming...From Staircases?">Learning Dynamic Programming...From Staircases?</a><time datetime="2025-07-19T07:15:44.000Z" title="Created 2025-07-19 00:15:44">2025-07-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/06/End-of-Sophomore-Recap/" title="End of Sophomore Recap">End of Sophomore Recap</a><time datetime="2025-06-07T00:53:07.000Z" title="Created 2025-06-06 17:53:07">2025-06-06</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2023 - 2026 By Yeedrag</span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script></div><!-- hexo injector body_end start -->
<script src="/js/collapse.js"></script>
<!-- hexo injector body_end end --></body></html>